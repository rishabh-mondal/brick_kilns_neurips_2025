{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b40de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "import torch\n",
    "import os\n",
    "# Basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Monitoring\n",
    "from tqdm.notebook import tqdm\n",
    "# IO\n",
    "from os.path import join, exists, basename, dirname, splitext, expanduser\n",
    "from glob import glob\n",
    "# Parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "\n",
    "\n",
    "from supervision.metrics import MeanAveragePrecision\n",
    "\n",
    "\n",
    "from supervision.metrics.core import Metric, MetricTarget\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import RTDETR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5e2bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base fold path: /home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/brick_kilns_neurips_2025/runs/detect\n",
      "Cross-validation base path: /home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/data/processed_data/crossval/dhaka_airshed_aa_labels_sentinel\n",
      "Model suffix: dhaka_airshed_aa_labels_sentinel_model_yolo12l_epochs_100_{}_128/weights/best.pt\n",
      "Model path: /home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/brick_kilns_neurips_2025/runs/detect/dhaka_airshed_aa_labels_sentinel_model_yolo12l_epochs_100_1_128/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set CUDA device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# Parameters\n",
    "region = \"dhaka_airshed\"  # First region (change this for the second region)\n",
    "task = \"aa\"\n",
    "type=\"detect\"\n",
    "image_size = 128  # Image size (128 or 640)\n",
    "sepecific_feature=\"none\"\n",
    "satellite_type = \"sentinel\"\n",
    "class_names = [\"CFCBK\", \"FCBK\", \"Zigzag\"]\n",
    "num_classes = len(class_names)\n",
    "CLASSES = class_names  # For sv.ConfusionMatrix\n",
    "model=\"yolo12l\"  # Model type (e.g., \"yolov8n\", \"yolov8s\", etc.)\n",
    "model_name = \"yolo12l-aa\"  # Model name (e.g., \"yolov8n\", \"yolov8s\", etc.)\n",
    "\n",
    "# Define paths\n",
    "base_fold_path = f\"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/brick_kilns_neurips_2025/runs/{type}\"\n",
    "print(f\"Base fold path: {base_fold_path}\")\n",
    "crossval_base_path = f\"/home/rishabh.mondal/Brick-Kilns-project/ijcai_2025_kilns/data/processed_data/crossval/{region}_{task}_labels_{satellite_type}\"\n",
    "print(f\"Cross-validation base path: {crossval_base_path}\")\n",
    "model_suffix = f\"{region}_{task}_labels_sentinel_model_{model}_epochs_100_{{}}_{image_size}/weights/best.pt\"\n",
    "print(f\"Model suffix: {model_suffix}\")\n",
    "# Check if the model path exists\n",
    "model_path = os.path.join(base_fold_path, model_suffix.format(1))\n",
    "\n",
    "print(f\"Model path: {model_path}\")  \n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model path does not exist: {model_path}\")\n",
    "# Check if the cross-validation path exists\n",
    "if not os.path.exists(crossval_base_path):\n",
    "    raise FileNotFoundError(f\"Cross-validation path does not exist: {crossval_base_path}\")\n",
    "# Check if the base fold path exists\n",
    "if not os.path.exists(base_fold_path):\n",
    "    raise FileNotFoundError(f\"Base fold path does not exist: {base_fold_path}\")\n",
    "# Check if the image size is valid\n",
    "if image_size not in [128, 640]:\n",
    "    raise ValueError(f\"Invalid image size: {image_size}. Must be one of [128, 640].\")\n",
    "# Check if the region is valid\n",
    "valid_regions = [\"wb_small_airshed\", \"lucknow_airshed\", \"delhi_airshed\", \"dhaka_airshed\"]\n",
    "if region not in valid_regions:\n",
    "    raise ValueError(f\"Invalid region: {region}. Must be one of {valid_regions}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "245dcf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü© Fold 0 Evaluation\n",
      "Loaded 96 test samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a24ad8a82d4e7aa68b6746e3aa3607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise mAP: [0, 0.0, 0.3030363792113265]\n",
      "\n",
      "üü© Fold 1 Evaluation\n",
      "Loaded 95 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e800fbb07c489eb3083df31d7ef694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise mAP: [0, 0.0, 0.4653407553483264]\n",
      "\n",
      "üü© Fold 2 Evaluation\n",
      "Loaded 95 test samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cfe11d83a742e7a24ac3d8d9b41aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise mAP: [0, 0.0, 0.40072656767546677]\n",
      "\n",
      "üü© Fold 3 Evaluation\n",
      "Loaded 95 test samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efbbfd27da244b785eb7d7798553815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise mAP: [0, 0.0, 0.408158844265575]\n",
      "‚úÖ Results saved with grid formatting:\n",
      "- Text: summary.txt\n",
      "- CSV : dhaka_airshed_crossval_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>üìç Cross-Validation Results ‚Äî yolo12l-aa - DHAKA AIRSHED-128</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "| Fold       | IoU   | Precision   | Recall      | F1 score    | TP           | FP             | FN             | Kiln instances   | mAP_cfcbk   | mAP_fcbk    | mAP_zigzag   |\n",
      "+============+=======+=============+=============+=============+==============+================+================+==================+=============+=============+==============+\n",
      "| 0          | 0.33  | 0.37        | 0.37        | 0.37        | 85.0         | 144.0          | 144.0          | 229.0            | 0           | 0.0         | 0.3          |\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "| 1          | 0.33  | 0.5         | 0.5         | 0.5         | 96.0         | 97.0           | 97.0           | 193.0            | 0           | 0.0         | 0.47         |\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "| 2          | 0.33  | 0.43        | 0.43        | 0.43        | 96.0         | 128.0          | 128.0          | 224.0            | 0           | 0.0         | 0.4          |\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "| 3          | 0.33  | 0.42        | 0.42        | 0.42        | 91.0         | 126.0          | 126.0          | 217.0            | 0           | 0.0         | 0.41         |\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "| mean ¬± std | -     | 0.43 ¬± 0.05 | 0.43 ¬± 0.05 | 0.43 ¬± 0.05 | 92.00 ¬± 5.23 | 123.75 ¬± 19.57 | 123.75 ¬± 19.57 | 215.75 ¬± 15.95   | 0.00 ¬± 0.00 | 0.00 ¬± 0.00 | 0.39 ¬± 0.07  |\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n",
      "| Fold       | IoU   | Precision   | Recall      | F1 score    | TP           | FP             | FN             | Kiln instances   | mAP_cfcbk   | mAP_fcbk    | mAP_zigzag   |\n",
      "+============+=======+=============+=============+=============+==============+================+================+==================+=============+=============+==============+\n",
      "| mean ¬± std | -     | 0.43 ¬± 0.05 | 0.43 ¬± 0.05 | 0.43 ¬± 0.05 | 92.00 ¬± 5.23 | 123.75 ¬± 19.57 | 123.75 ¬± 19.57 | 215.75 ¬± 15.95   | 0.00 ¬± 0.00 | 0.00 ¬± 0.00 | 0.39 ¬± 0.07  |\n",
      "+------------+-------+-------------+-------------+-------------+--------------+----------------+----------------+------------------+-------------+-------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a temporary YAML file\n",
    "data_yml_save_path = mkdtemp()\n",
    "data_yml_path = os.path.join(data_yml_save_path, \"data.yml\")\n",
    "with open(data_yml_path, \"w\") as f:\n",
    "    f.write(f\"\"\"train: dummy\n",
    "val: dummy\n",
    "nc: {num_classes}\n",
    "names: {class_names}\n",
    "\"\"\")\n",
    "\n",
    "# Initialize results DataFrame\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Fold', 'IoU', 'Precision', 'Recall', 'F1 score', \n",
    "    'TP', 'FP', 'FN', 'Kiln instances', 'mAP_cfcbk', 'mAP_fcbk', 'mAP_zigzag'\n",
    "])\n",
    "\n",
    "# Evaluate each fold\n",
    "for fold in range(0,4):\n",
    "    print(f\"\\nüü© Fold {fold} Evaluation\")\n",
    "\n",
    "    # Paths\n",
    "    model_path = os.path.join(base_fold_path, model_suffix.format(fold))\n",
    "    test_image_dir = os.path.join(crossval_base_path, str(fold), \"test/images\")\n",
    "    test_label_dir = os.path.join(crossval_base_path, str(fold), \"test/labels\")\n",
    "\n",
    "    # Load dataset\n",
    "    sv_dataset = sv.DetectionDataset.from_yolo(test_image_dir, test_label_dir, data_yml_path,is_obb=False)\n",
    "    print(f\"Loaded {len(sv_dataset)} test samples\")\n",
    "\n",
    "    # Load model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    targets, predictions = [], []\n",
    "\n",
    "    # Inference loop\n",
    "    for name, _, gt_detection in tqdm(sv_dataset):\n",
    "        result = model(\n",
    "            name,\n",
    "            imgsz=image_size,\n",
    "            iou=0.33,\n",
    "            conf=0.25,\n",
    "            max_det=300,\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        prediction = sv.Detections.from_ultralytics(result)\n",
    "        predictions.append(prediction)\n",
    "        targets.append(gt_detection)\n",
    "\n",
    "    # mAP Calculation\n",
    "    mAP_metric = MeanAveragePrecision(class_agnostic=False)\n",
    "    mAP_result = mAP_metric.update(predictions, targets).compute()\n",
    "    class_wise_mAP = [0] * num_classes\n",
    "    for cls, mAP in zip(mAP_result.matched_classes.tolist(), mAP_result.ap_per_class[:, 0].tolist()):\n",
    "        class_wise_mAP[cls] = mAP\n",
    "    print(f\"Class-wise mAP: {class_wise_mAP}\")\n",
    "\n",
    "    # Confusion Matrix and Metrics at IoU=0.5\n",
    "    iou_threshold = 0.33\n",
    "    cm = sv.ConfusionMatrix.from_detections(\n",
    "        predictions=predictions,\n",
    "        targets=targets,\n",
    "        classes=CLASSES,\n",
    "        conf_threshold=0.25,\n",
    "        iou_threshold=iou_threshold\n",
    "    ).matrix\n",
    "\n",
    "    # True Positives\n",
    "    tp = sum(cm[i][i] for i in range(num_classes))\n",
    "\n",
    "    # Predicted Positives (Columns sum)\n",
    "    predicted_positives = cm.sum(axis=0).sum()\n",
    "\n",
    "    # Actual Positives (Rows sum)\n",
    "    actual_positives = cm.sum(axis=1).sum()\n",
    "\n",
    "    # Precision, Recall, F1 Score\n",
    "    precision = tp / (predicted_positives + 1e-9)\n",
    "    recall = tp / (actual_positives + 1e-9)\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "    fp = predicted_positives - tp\n",
    "    fn = actual_positives - tp\n",
    "\n",
    "    # Append results\n",
    "    # Append results\n",
    "    results_df = pd.concat([\n",
    "        results_df,\n",
    "        pd.DataFrame([{\n",
    "            'Fold': fold,\n",
    "            'IoU': round(iou_threshold, 2),\n",
    "            'Precision': round(precision, 2),\n",
    "            'Recall': round(recall, 2),\n",
    "            'F1 score': round(f1_score, 2),\n",
    "            'TP': tp,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'Kiln instances': actual_positives,\n",
    "            'mAP_cfcbk': round(class_wise_mAP[0], 2),\n",
    "            'mAP_fcbk': round(class_wise_mAP[1], 2),\n",
    "            'mAP_zigzag': round(class_wise_mAP[2], 2)\n",
    "        }])\n",
    "    ], ignore_index=True)\n",
    "\n",
    "# Compute mean and variance for all numeric columns (excluding 'Fold' and 'IoU')\n",
    "metrics_to_summarize = ['Precision', 'Recall', 'F1 score', 'TP', 'FP', 'FN', 'Kiln instances', 'mAP_cfcbk', 'mAP_fcbk', 'mAP_zigzag']\n",
    "mean_values = results_df[metrics_to_summarize].mean()\n",
    "std_values = results_df[metrics_to_summarize].std()\n",
    "\n",
    "# Format as \"mean ¬± std\"\n",
    "summary_row = {\n",
    "    'Fold': 'mean ¬± std',\n",
    "    'IoU': '-'\n",
    "}\n",
    "for metric in metrics_to_summarize:\n",
    "    summary_row[metric] = f\"{mean_values[metric]:.2f} ¬± {std_values[metric]:.2f}\"\n",
    "\n",
    "# Append the formatted summary row\n",
    "results_df = pd.concat([\n",
    "    results_df,\n",
    "    pd.DataFrame([summary_row])\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = f\"{region}_crossval_results.csv\"\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Create formatted table with grid lines\n",
    "region_title = f\"üìç Cross-Validation Results ‚Äî {model_name} - {region.replace('_', ' ').upper()}-{image_size}\"\n",
    "table_string = tabulate(results_df, headers='keys', tablefmt='grid', showindex=False)\n",
    "\n",
    "# Save to TXT (append mode)\n",
    "txt_path = \"summary.txt\"  # Change this to your desired path\n",
    "with open(txt_path, \"a\") as f:  # Open in append mode\n",
    "    f.write(f\"\\n{region_title.center(120)}\\n\\n\")\n",
    "    f.write(table_string)\n",
    "\n",
    "print(f\"‚úÖ Results saved with grid formatting:\\n- Text: {txt_path}\\n- CSV : {csv_path}\")\n",
    "# Display the table in Jupyter Notebook\n",
    "display(HTML(f\"<h3>{region_title}</h3>\"))\n",
    "# Display the table\n",
    "print(\"\\n\" + table_string)\n",
    "# Display the summary\n",
    "print(\"\\n\" + tabulate(pd.DataFrame([summary_row]), headers='keys', tablefmt='grid', showindex=False))\n",
    "# Display the summary in Jupyter Notebook\n",
    "# display(HTML(tabulate(pd.DataFrame([summary_row]), headers='keys', tablefmt='grid', showindex=False).replace('\\n', '<br>')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dfc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rishabh_sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
